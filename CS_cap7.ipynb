{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Código 7.0:  Bibliotecas e programas %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "#                 rode sempre este código antes dos demais\n",
        "\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm  # saida mais detalhada que LogisticRegression do sklearn.linear_model\n",
        "# sm.logit usa método de maxima verossimilhança (tradicional) para rodar a logística\n",
        "#o LogisticRegression usa uma implementação de otimização que pode ser ajustado dependendo do parâmetro solver\n",
        "from sklearn.metrics import roc_curve, auc,accuracy_score, precision_score, recall_score, f1_score,matthews_corrcoef,confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SlDehdYfPvVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4RU4jnyjoYs"
      },
      "outputs": [],
      "source": [
        "# Código 7.1: Criando o dataframe kim %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "# Primeiro baixe o arquivo Kimsport6 do github e salve em seu computador\n",
        "# faça o upload do arquivo no colab\n",
        "kim=pd.read_excel('/content/sample_data/Kimsport6.xlsx')\n",
        "display(kim.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Código 7.2: Separação em duas amostras - treinamento e teste %%%%%%%%%%%%%%%%%\n",
        "\n",
        "\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "print(X.columns)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "\n",
        "# Verificar os tamanhos dos conjuntos e as proporções de STATUS\n",
        "print(\"Tamanho do conjunto de treinamento:\", X_train.shape)\n",
        "print(\"Tamanho do conjunto de teste:\", X_test.shape)\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(normalize=True,dropna=False).sort_index()\n",
        "print(frequencia_train)\n",
        "frequencia_test = y_test['STATUS_MP'].value_counts(normalize=True,dropna=False).sort_index()\n",
        "print(frequencia_test)"
      ],
      "metadata": {
        "id": "HwQ5PpOPkPYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Código 7.3:  Regressao Logística utilizando Backward Selection %%%%%%%%%%%%%%\n",
        "\n",
        "X_train = sm.add_constant(X_train) # sm.logit necessita inclusao de beta(zero)\n",
        "\n",
        "#rodando e selecionando as variáveis ==========================================\n",
        "def backward_elimination(X_train, y_train, significance_level=0.15):\n",
        "    # Ajustando o modelo de regressão logística\n",
        "    model = sm.Logit(y_train, X_train)\n",
        "    result = model.fit()\n",
        "\n",
        "    # Mostrando o resumo  do modelo com todas as preditoras\n",
        "    print(\"Resumo do modelo inicial:\")\n",
        "    print(result.summary())\n",
        "\n",
        "    # Realizando a eliminação backward\n",
        "    while max(result.pvalues) > significance_level:\n",
        "        # Identificar o maior p-valor\n",
        "        max_p_value = result.pvalues.idxmax()\n",
        "\n",
        "        # Remover a variável com o maior p-valor\n",
        "        print(f\"\\nRemovendo a variável: {max_p_value} com p-valor: {result.pvalues[max_p_value]}\")\n",
        "        X_train = X_train.drop(columns=[max_p_value])\n",
        "\n",
        "        # Ajustando o modelo novamente com as variáveis restantes\n",
        "        model = sm.Logit(y_train, X_train)\n",
        "        result = model.fit()\n",
        "\n",
        "    # Resumo final do modelo após a eliminação\n",
        "    print(\"\\nResumo final após backward elimination:\")\n",
        "    print(result.summary())\n",
        "\n",
        "    return result, X_train\n",
        "#cuidado: result só existe dentro da função. Nao é valor salvo\n",
        "#===============================================================================\n",
        "# Executando a eliminação backward com a amostra de treinamento\n",
        "final_model, X_selected = backward_elimination(X_train, y_train)\n",
        "# O modelo final está em final_model, e as variáveis selecionadas em X_selected\n",
        "print(X_selected.columns)\n",
        "#===============================================================================\n",
        "# colocando colunas em X_test para ficar igual a X_selected\n",
        "#(ou seja,, sem as vars elinminadas no Bward)\n",
        "selected_columns = X_selected.columns[1:]\n",
        "# Filter X_test using selected_columns\n",
        "X_test = X_test[selected_columns]\n",
        "X_test = sm.add_constant(X_test)  # Add constant back to X_test\n",
        "#===============================================================================\n",
        "#Previsões das probabilidades de mau pagador\n",
        "y_pred_prob = final_model.predict(X_test)\n",
        "print(\"\\n probs. prevista\",y_pred_prob.head(3))\n",
        "#===============================================================================\n",
        "# gerando um arquivo com todas as colunas de X_test usadas no modelo\n",
        "# e as probabilidade prevista de ser mau pagador y_pred_prob ==> X_FINAL\n",
        "X_FINAL=X_test.copy()\n",
        "X_FINAL['y_pred_prob'] = y_pred_prob\n",
        "# Exibindo o DataFrame atualizado\n",
        "print(X_FINAL.head(3))\n",
        "#===============================================================================\n",
        "# Calcular a curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "# Calcular a AUC (Área sob a Curva)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Plotar a curva ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "# Exibir a AUC\n",
        "print(f'AUC: {roc_auc:.2f}')\n",
        "#===============================================================================\n",
        "# Avaliação do modelo para um ponto de corte PC\n",
        "PC=0.5\n",
        "y_pred = final_model.predict(X_test)\n",
        "y_pred = (y_pred_prob >= PC).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "MCC=matthews_corrcoef(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "frequencia_test = y_test['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"frequencia de bons (0) e maus (1) pagadores\",frequencia_test)\n",
        "\n",
        "print(\"\\n Acurácia:\", accuracy)\n",
        "print(\"Precisão:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Mathews correlation coeficient:\", f1)\n",
        "print(\"Matriz de Classificação:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "zRyU8LfBscFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Código 7.4: seleção de variáveis utilizando AIC - Akaike infrormation criteria\n",
        "#   apenas uma ilustração desta forma de seleção de variáveis, nao está no texto\n",
        "#   programa seleciona a variavel a remover usando p-value;\n",
        "#   depois calcula AIC e vê se melhorou (redução de AIC)\n",
        "# (o software R tem um algoritmo melhor para usar AIC)\n",
        "\n",
        "#repetindo separação pois arquivos foram modificados no código 7.3 acima\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "print(X.columns)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "\n",
        "# Adicionar constante (para manter o intercepto no modelo)\n",
        "X_train_const = sm.add_constant(X_train)\n",
        "X_test_const = sm.add_constant(X_test)\n",
        "\n",
        "# Função para AIC backward selection mantendo o intercepto\n",
        "def backward_selection(X, y):\n",
        "    model = sm.Logit(y, X).fit(disp=1)  # Ajusta modelo inicial\n",
        "    print(f\"Modelo inicial - AIC: {model.aic:.4f} - Variáveis: {list(X.columns)}\\n\")\n",
        "    print(model.summary())\n",
        "    while True:\n",
        "        aic = model.aic\n",
        "        pvalues = model.pvalues.drop(\"const\")  # Remove apenas a constante da análise\n",
        "        if pvalues.empty:\n",
        "            break\n",
        "        worst_pval = pvalues.max()  # Variável com maior p-valor\n",
        "        if worst_pval > 0.15:  # Limite de significância\n",
        "            worst_feature = pvalues.idxmax()\n",
        "            X = X.drop(columns=[worst_feature])  # Remove variável\n",
        "            model = sm.Logit(y, X).fit(disp=0)  # Reajusta modelo\n",
        "            print(f\"Removendo '{worst_feature}' - Novo AIC: {model.aic:.4f} - Variáveis: {list(X.columns)}\")\n",
        "            if model.aic >= aic:  # Se AIC não melhorar, para\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    print(\"\\nSeleção final concluída!\\n\")\n",
        "    return model, X\n",
        "\n",
        "# Aplicar seleção de variáveis\n",
        "modelo_final, X_train_final = backward_selection(X_train_const, y_train)\n",
        "print(\"\\n\", modelo_final.summary())\n",
        "\n",
        "# Ajustar modelo final e fazer previsões no conjunto de teste\n",
        "X_test_final = X_test_const[X_train_final.columns]  # Manter mesmas colunas\n",
        "\n",
        "PC=0.5\n",
        "y_pred_probAIC = modelo_final.predict(X_test_final) #com AIC\n",
        "y_pred_classAIC = (y_pred_prob2 >= PC).astype(int)  # Converter para classes binárias\n"
      ],
      "metadata": {
        "id": "161ko0JqL-KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Código 7.5: gerando um arquivo com todas as colunas de X_test e as probabilidade previstas ==> kim_final_reglog\n",
        "\n",
        "kim_final_reglog=X_test.copy()\n",
        "kim_final_reglog[\"status_mp\"]=y_test\n",
        "kim_final_reglog['y_pred_prob'] = y_pred_prob\n",
        "\n",
        "# Exibindo o DataFrame atualizado\n",
        "print(kim_final_reglog.head(3))\n",
        "\n",
        "!pip install openpyxl > /dev/null\n",
        "kim_final_reglog.to_excel('kim_final_reglog.xlsx', index=False)\n",
        "from google.colab import files\n",
        "files.download('kim_final_reglog.xlsx')"
      ],
      "metadata": {
        "id": "YRO9ABan7hXj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}