{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Código 8.0:  Bibliotecas e programas %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "#                 rode sempre este código antes dos demais\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "! pip install xgboost lime scikit-learn  > /dev/null\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import log_loss, roc_curve, auc,accuracy_score\n",
        "import shap"
      ],
      "metadata": {
        "id": "VLEil8N7sKLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rVu4nrQxeQC"
      },
      "outputs": [],
      "source": [
        "# Código 8.1: Criando o dataframe kim %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "# Primeiro baixe o arquivo Kimsport6 do github e salve em seu computador\n",
        "# faça o upload do arquivo no colab\n",
        "kim=pd.read_excel('/content/sample_data/Kimsport6.xlsx')\n",
        "display(kim.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Código 8.2: Árvore de classificação simples %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "#===============================================================================\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "print(X.columns)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "#===============================================================================\n",
        "# Criar e treinar a árvore de decisão\n",
        "arvore = DecisionTreeClassifier(max_depth=2) # 2 pois é apenas ilustração\n",
        "arvore.fit(X, y)\n",
        "#===============================================================================\n",
        "# Visualizar a árvore\n",
        "plt.figure(figsize=(10, 6))  # Configurar o tamanho da imagem\n",
        "class_names = [str(name) for name in y.STATUS_MP.unique()]\n",
        "plot_tree(arvore, feature_names=X.columns, class_names=class_names,\n",
        "          filled=False,impurity=False,proportion=True, precision=1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GMSdxyqvWSOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Código 8.3: Random Forest utilizando bootsrtapping (default) %%%%%%%%%%%%%%%%%\n",
        "kim=pd.read_excel('/content/sample_data/Kimsport6.xlsx')\n",
        "display(kim.head(3))\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "print(X.columns)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "#===============================================================================\n",
        "start = time.time()  # Marca o início do processamento\n",
        "rf = RandomForestClassifier(random_state=18,\n",
        "                            min_samples_split=100,\n",
        "                            min_samples_leaf=50,\n",
        "                            bootstrap=True,\n",
        "                            oob_score=True)  # Usar amostras OOB para validação\n",
        "# grid de valores para otimização - critério AUROC\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300], # número de rodadas\n",
        "    'max_depth': [10, 15, 25], # profundidade da árvore / qto maior, maior o risco de overfitting\n",
        "    'max_features': ['sqrt', 'log2']} #quantidade de vars a serem selecionadas\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=-1, verbose=2)\n",
        "#n_jobs=-1: Usará todos os núcleos de CPU disponíveis no seu computador para executar a busca\n",
        "#o critério de avaliação é especificado pelo parâmetro scoring. Eu prefiro AUROC\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Mostrar os resultados de AUC para cada combinação de parâmetros\n",
        "# grid_search.cv_results_ contém os resultados de todas as combinações\n",
        "results = grid_search.cv_results_\n",
        "# Exibir os valores de AUC para cada combinação de hiperparâmetros\n",
        "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
        "    print(f\"AUC: {mean_score:.4f} | Hiperparâmetros: {params}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Melhores parâmetros encontrados:\", grid_search.best_params_)\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "#===============================================================================\n",
        "# previsões com amostra teste\n",
        "y_pred = best_rf_model.predict(X_test) #classificação prevista PC=0,5 é default\n",
        "y_pred_prob = best_rf_model.predict_proba(X_test)[:, 1] # probMP que é class=1\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\n\")\n",
        "print(f'Acurácia no conjunto de teste para melhor modelo \\n: {accuracy:.4f}')\n",
        "fpr, tpr, thresholds = roc_curve(y_test.iloc[:, 0], y_pred_prob)\n",
        "auc_score = auc(fpr, tpr)\n",
        "print(\"\\n\")\n",
        "print(f'AUC no conjunto de teste para melhor modelo \\n: {auc_score:.4f}')\n",
        "print(\"\\n\")\n",
        "#===============================================================================\n",
        "# importância de cada variável (critério interno de RandomForestClassifier)\n",
        "\n",
        "importances = best_rf_model.feature_importances_\n",
        "# Ordenar as importâncias em ordem decrescente\n",
        "indices = np.argsort(importances)[::-1]\n",
        "# Visualizar as 10 variáveis mais importantes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Importância das Variáveis\")\n",
        "plt.barh(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
        "plt.yticks(range(X_train.shape[1]), X_train.columns[indices])\n",
        "plt.xlabel(\"Importância\")\n",
        "plt.show()\n",
        "#calculo do tempo de processamento\n",
        "end = time.time()  # Marca o fim do RF\n",
        "print(f\"\\n\\nTempo de execução: {end - start:.4f} segundos\")\n",
        "#==============================================================================\n",
        "# gerando arquivo com colunas de X_test e as probs previstas ==> kim_final_RF\n",
        "kim_final_RF=X_test.copy()\n",
        "kim_final_RF[\"status_mp\"]=y_test\n",
        "kim_final_RF['y_pred_prob'] = y_pred_prob\n",
        "# Exibindo o DataFrame atualizado\n",
        "print(kim_final_RF.head(5))\n",
        "\n",
        "!pip install openpyxl > /dev/null\n",
        "kim_final_RF.to_excel('kim_final_RF.xlsx', index=False)\n",
        "from google.colab import files\n",
        "files.download('kim_final_RF.xlsx')"
      ],
      "metadata": {
        "id": "xrxxBDaJE_Sq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Código 8.4: XGBOOST & e importância das variáveis com SHAP #%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "#==============================================================================\n",
        "kim=pd.read_excel('/content/sample_data/Kimsport6.xlsx')\n",
        "display(kim.head(3))\n",
        "\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "print(X.columns)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "# Sseparando amostras\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "#===============================================================================\n",
        "start = time.time()  # Marca o início do processamento\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [4,7],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'min_child_weight': [10,20]\n",
        "}\n",
        "model = xgb.XGBClassifier(objective='binary:logistic',\n",
        "                          eval_metric='logloss',early_stopping_rounds=10,learning_rate=0.1,\n",
        "                          use_label_encoder=False)\n",
        "#aqui, por exemplo, selecionamos logloss para medir performance\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_log_loss',\n",
        "    cv=3,  # Cross-validation com 3 folds\n",
        "    verbose=1,\n",
        "    n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train,  eval_set=[(X_test, y_test)], verbose=False)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Para acessar o número de iterações antes de ocorrer o early stop:\n",
        "aux=best_model.get_booster().best_iteration\n",
        "print(f'Número de árvores necessarias (early stop):  {aux}')\n",
        "#==============================================================================\n",
        "# Predição e cálculo do LogLoss\n",
        "y_pred_prob = best_model.predict_proba(X_test)[:, 1]\n",
        "log_loss_value = log_loss(y_test, y_pred_prob)\n",
        "print(f'\\nLogLoss no conjunto de validação: {log_loss_value:.4f}')\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test.iloc[:, 0], y_pred_prob)\n",
        "auc_score = auc(fpr, tpr)\n",
        "print(\"\\n\")\n",
        "print(f'AUC no conjunto de teste para melhor modelo: {auc_score:.4f}')\n",
        "print(\"\\n\")\n",
        "print(\"Melhores parâmetros encontrados:\", grid_search.best_params_)\n",
        "end = time.time()  # Marca o fim do xgb\n",
        "print(f\"\\n\\nTempo de execução: {end - start:.4f} segundos\")\n",
        "#==============================================================================\n",
        "# SHAP\n",
        "explainer = shap.Explainer(best_model)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# Plot da importância das variáveis com SHAP\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "shap.plots.bar(shap_values, max_display=15, show=False)\n",
        "bars = ax.patches  # List of the bars\n",
        "# Change the color of each bar\n",
        "for bar in bars:\n",
        "    bar.set_facecolor('gray')  # cor das barras\n",
        "for text in plt.gca().texts:  #apaga os rótulos\n",
        "    text.set_visible(False)\n",
        "plt.title(\"Importância das preditoras\", fontsize=12, fontweight=\"bold\")  # Título do gráfico\n",
        "plt.xlabel(\"average absolute values of the SHAP values on all the training instances \\n mean|SHAPvalues|\", fontsize=8)  # Nome do eixo X\n",
        "plt.ylabel(\"\", fontsize=12)       # Nome do eixo Y\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "#===============================================================================\n",
        "# gerando arquivo com todas as colunas de X_test e as probabilidade previstas ==> kim_final_xgb\n",
        "\n",
        "kim_final_xgb=X_test.copy()\n",
        "kim_final_xgb[\"status_mp\"]=y_test\n",
        "kim_final_xgb['y_pred_prob'] = y_pred_prob\n",
        "\n",
        "# Exibindo o DataFrame atualizado\n",
        "print(kim_final_xgb.head(5))\n",
        "\n",
        "!pip install openpyxl > /dev/null\n",
        "kim_final_xgb.to_excel('kim_final_xgb.xlsx', index=False)\n",
        "from google.colab import files\n",
        "files.download('kim_final_xgb.xlsx')"
      ],
      "metadata": {
        "id": "1kctQpr-D5Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Código 8.5: Importância das variáveis com medida interna do xgb (Ganho)%%%%%%\n",
        "#Média do ganho que a variável trouxe para a árvore.\n",
        "#Considerando as vezes em participou\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "xgb.plot_importance(best_model, importance_type='gain',show_values=False, ax=ax)\n",
        "ax.set_ylabel('', fontsize=10)\n",
        "ax.set_xlabel('Importância', fontsize=12)\n",
        "ax.set_title('Importância das Variáveis (Ganho)', fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oq_6UFI_maAl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}