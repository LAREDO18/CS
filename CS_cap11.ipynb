{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Código 11.0:  Bibliotecas e programas %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "#                 rode sempre este código antes dos demais\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LogisticRegression #permite ponderação\n",
        "# sm.logit usa maxima verossimilhança (tradicional)\n",
        "# LogisticRegression usa estimação  via solver\n",
        "import shap\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, auc\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score,matthews_corrcoef,confusion_matrix, log_loss\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dx46CeJkx0-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Código 11.1: Criando o dataframe  kim   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "# Primeiro baixe os arquivos Kimsport e  Kimsport5 do github\n",
        "# salve em seu computador\n",
        "# faça o upload do arquivo no colab\n",
        "#rode kim=pd.read_excel('/content/sample_data/Kimbal.xlsx') antes de cada algoritmo\n",
        "#  pois x_train e X_test saõ modificados a cada rodada"
      ],
      "metadata": {
        "id": "PW3Q1w9tx6Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Código 11.2:REGLOG sem balanceamento\n",
        "kim=pd.read_excel('/content/sample_data/Kimbal.xlsx')\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "frequenciaoriginal = y.value_counts(dropna=False).sort_index()\n",
        "print(\"frequencia amostra original :\", frequenciaoriginal)\n",
        "################################################################################\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de treinamento:\", frequencia_train)\n",
        "frequencia_test = y_test['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de teste:\", frequencia_test)\n",
        "#==============================================================================\n",
        "# rodando a regressao sem Backward selection (preguiça....)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "modelo = LogisticRegression( max_iter=1000, random_state=18)\n",
        "modelo.fit(X_train, y_train)\n",
        "print(\"Intercepto:\", modelo.intercept_[0])\n",
        "y_pred_prob = modelo.predict_proba(X_test)[:, 1]\n",
        "coef = pd.Series(modelo.coef_[0], index=X_train.columns)\n",
        "print(coef)\n",
        "#==============================================================================\n",
        "print(\"\\n\\nAvaliação de REGLOG sem balanceamento de amostras\")\n",
        "# Calcular a curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "# Calcular a AUC (Área sob a Curva)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Exibir a AUC\n",
        "print(f'\\nAUC da curva ROC sem balanceamento: {roc_auc:.2f}')\n",
        "\n",
        "#PRcurve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "# Calculando a AUC da curva Precision-Recall\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"\\nAUC da curva Precision-Recall: {pr_auc:.2f}\")\n",
        "#==============================================================================\n",
        "# Avaliação do modelo com ponto de corte PC\n",
        "print(\"\\nAvaliação sem balanceamento de amostras\")\n",
        "\n",
        "PC=0.25\n",
        "\n",
        "y_pred = (y_pred_prob >= PC).astype(int)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "MCC=matthews_corrcoef(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\nMatriz de Classificação com PC={PC}\")\n",
        "conf_matrix=pd.DataFrame(conf_matrix)\n",
        "conf_matrix = np.array(conf_matrix)\n",
        "df_conf_matrix = pd.DataFrame(conf_matrix, index=['Real BP', 'Real MP'], columns=['Predito BP', 'Predito MP'])\n",
        "print(df_conf_matrix)\n",
        "print(f\"\\nPrecisão:, {precision:.2f}\")\n",
        "print(f\"Recall:, {recall:.2f}\")\n",
        "print(f\"F1-score:, {f1:.2f}\")\n",
        "print(f\"Mathews correlation coeficient:, {MCC:.2f}\")"
      ],
      "metadata": {
        "id": "V6BDrzTY7rVE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Código 11.3: REG LOG sem balanceamento, mas...ponderando observações\n",
        "#==============================================================================\n",
        "# Primeiro faça o upload do arquivo\n",
        "kim=pd.read_excel('/content/sample_data/Kimbal.xlsx')\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "#==============================================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de treinamento:\", frequencia_train)\n",
        "frequencia_test = y_test['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de teste:\", frequencia_test)\n",
        "#==============================================================================\n",
        "modelo = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=18)\n",
        "modelo.fit(X_train, y_train)\n",
        "print(\"Intercepto:\", modelo.intercept_[0])\n",
        "y_pred_prob = modelo.predict_proba(X_test)[:, 1]\n",
        "coef = pd.Series(modelo.coef_[0], index=X_train.columns)\n",
        "print(coef)\n",
        "#==============================================================================\n",
        "#Avaliação via AUC\n",
        "\n",
        "# Calcular a curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "# Calcular a AUC (Área sob a Curva)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Exibir a AUC\n",
        "print(f'\\nAUC da curva ROC sem balanceamento: {roc_auc:.2f}')\n",
        "\n",
        "#PRcurve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "# Calculando a AUC da curva Precision-Recall\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"\\nAUC da curva Precision-Recall: {pr_auc:.2f}\")\n",
        "#==============================================================================\n",
        "# Avaliação do modelo com ponto de corte PC\n",
        "print(\"\\nAvaliação sem balanceamento de amostras\")\n",
        "PC=0.6\n",
        "\n",
        "y_pred = (y_pred_prob >= PC).astype(int)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "MCC=matthews_corrcoef(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nMatriz de Classificação com PC={PC}\")\n",
        "conf_matrix=pd.DataFrame(conf_matrix)\n",
        "conf_matrix = np.array(conf_matrix)\n",
        "df_conf_matrix = pd.DataFrame(conf_matrix, index=['Real BP', 'Real MP'], columns=['Predito BP', 'Predito MP'])\n",
        "print(\"\\n\",df_conf_matrix)\n",
        "print(f\"\\nPrecisão:, {precision:.2f}\")\n",
        "print(f\"Recall:, {recall:.2f}\")\n",
        "print(f\"F1-score:, {f1:.2f}\")\n",
        "print(f\"Mathews correlation coeficient:, {MCC:.2f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T5kgb3hXT3nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Código 11.4:  REGLOG com undersampling método RUS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "#rodar logística com sm, utilizando BW com p values alfa=0,15\n",
        "#==============================================================================\n",
        "# Primeiro faça o upload do arquivo\n",
        "kim=pd.read_excel('/content/sample_data/Kimbal.xlsx')\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "#==============================================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de treinamento:\", frequencia_train)\n",
        "frequencia_test = y_test['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de teste:\", frequencia_test)\n",
        "#==============================================================================\n",
        "#balanceando com RUS\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de treinamento com RUS:\", frequencia_train)\n",
        "#==============================================================================\n",
        "X_train = sm.add_constant(X_train)\n",
        "def backward_elimination(X_train, y_train, significance_level=0.15):\n",
        "    # Ajustando o modelo de regressão logística\n",
        "    model = sm.Logit(y_train, X_train)\n",
        "    result = model.fit(disp=0)\n",
        "    # Realizando a eliminação BWard\n",
        "    while max(result.pvalues) > significance_level:\n",
        "        # Identificar o maior p-valor\n",
        "        max_p_value = result.pvalues.idxmax()\n",
        "\n",
        "        # Remover a variável com o maior p-valor\n",
        "        #print(f\"\\nRemovendo a variável: {max_p_value} com p-valor: {result.pvalues[max_p_value]}\")\n",
        "        X_train = X_train.drop(columns=[max_p_value])\n",
        "\n",
        "        # Ajustando o modelo novamente com as variáveis restantes\n",
        "        model = sm.Logit(y_train, X_train)\n",
        "        result = model.fit(disp=0)\n",
        "    return result, X_train\n",
        "#cuidado: result só existe dentro da função. Nao é valor salvo\n",
        "\n",
        "# Executando a eliminação BW com o conjunto de treino balanceado\n",
        "final_model, X_selected = backward_elimination(X_train, y_train)\n",
        "# O modelo final está em final_model, e as variáveis selecionadas em X_selected\n",
        "# colocando colunas em X_test para ficar igual a X_selected\n",
        "selected_columns = X_selected.columns[1:]\n",
        "# Filter X_test using selected_columns\n",
        "X_test = X_test[selected_columns]\n",
        "X_test = sm.add_constant(X_test)  # Add constant back to X_test\n",
        "#==============================================================================\n",
        "y_pred_prob = final_model.predict(X_test)\n",
        "\n",
        "print(\"\\n\\nAvaliação com balanceamento com RUS =============================\")\n",
        "# Calcular a curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "# Calcular a AUC (Área sob a Curva)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Exibir a AUC\n",
        "print(f'\\nAUC da curva ROC com RUS: {roc_auc:.2f}')\n",
        "\n",
        "#PRcurve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "# Calculando a AUC da curva Precision-Recall\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"\\nAUC da curva Precision-Recall com RUS: {pr_auc:.2f}\")\n",
        "#==============================================================================\n",
        "# Avaliação do modelo com ponto de corte\n",
        "\n",
        "PC=0.7\n",
        "\n",
        "y_pred = (y_pred_prob >= PC).astype(int)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "MCC=matthews_corrcoef(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nMatriz de Classificação com PC=\",PC)\n",
        "conf_matrix=pd.DataFrame(conf_matrix)\n",
        "conf_matrix = np.array(conf_matrix)\n",
        "df_conf_matrix = pd.DataFrame(conf_matrix, index=['Real BP', 'Real MP'], columns=['Predito BP', 'Predito MP'])\n",
        "print(\"\\n\",df_conf_matrix)\n",
        "print(f\"\\nPrecisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "print(f\"Mathews correlation coeficient: {MCC:.2f}\")"
      ],
      "metadata": {
        "id": "Ac-B6lI2Lj3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Código 11.5: REGLOG com oversampling método SMOTE\n",
        "#rodar logística\n",
        "#utilizando BW com p values alfa=0,15\n",
        "#==============================================================================\n",
        "# Primeiro faça o upload do arquivo\n",
        "import pandas as pd\n",
        "kim=pd.read_excel('/content/sample_data/Kimbal.xlsx')\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "frequenciaoriginal = y.value_counts(dropna=False).sort_index()\n",
        "print(\"frequencia amostra original :\", frequenciaoriginal)\n",
        "#==============================================================================\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de treinamento:\", frequencia_train)\n",
        "frequencia_test = y_test['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de teste:\", frequencia_test)\n",
        "#==============================================================================\n",
        "# correção SMOTE para a amostra de treinamento\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smo = SMOTE(random_state=18)\n",
        "X_train, y_train = smo.fit_resample(X_train, y_train)\n",
        "frequencia_train = y_train.value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra treinamento com SMOTE:\",frequencia_train)\n",
        "#==============================================================================\n",
        "X_train = sm.add_constant(X_train)\n",
        "def backward_elimination(X_train, y_train, significance_level=0.15):\n",
        "    # Ajustando o modelo de regressão logística\n",
        "    model = sm.Logit(y_train, X_train)\n",
        "    result = model.fit(disp=0)\n",
        "    # Realizando a eliminação BWard\n",
        "    while max(result.pvalues) > significance_level:\n",
        "        # Identificar o maior p-valor\n",
        "        max_p_value = result.pvalues.idxmax()\n",
        "\n",
        "        # Remover a variável com o maior p-valor\n",
        "        #print(f\"\\nRemovendo a variável: {max_p_value} com p-valor: {result.pvalues[max_p_value]}\")\n",
        "        X_train = X_train.drop(columns=[max_p_value])\n",
        "\n",
        "        # Ajustando o modelo novamente com as variáveis restantes\n",
        "        model = sm.Logit(y_train, X_train)\n",
        "        result = model.fit(disp=0)\n",
        "    return result, X_train\n",
        "# Executando a eliminação BW com o conjunto de treino\n",
        "final_model, X_selected = backward_elimination(X_train, y_train)\n",
        "# colocando colunas em X_test para ficar igual a X_selected\n",
        "selected_columns = X_selected.columns[1:]\n",
        "# Filter X_test using selected_columns\n",
        "X_test = X_test[selected_columns]\n",
        "X_test = sm.add_constant(X_test)  # Add constant back to X_test\n",
        "#==============================================================================\n",
        "y_pred_prob = final_model.predict(X_test)\n",
        "\n",
        "print(\"\\n\\nAvaliação com balanceamento com SMOTE =============================\")\n",
        "# Calcular a curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "# Calcular a AUC (Área sob a Curva)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Exibir a AUC\n",
        "print(f'\\nAUC da curva ROC com SMOTE: {roc_auc:.2f}')\n",
        "\n",
        "#PRcurve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "# Calculando a AUC da curva Precision-Recall\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"\\nAUC da curva Precision-Recall com SMOTE: {pr_auc:.2f}\")\n",
        "#==============================================================================\n",
        "# Avaliação do modelo\n",
        "PC=0.4\n",
        "y_pred = (y_pred_prob >= PC).astype(int)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "MCC=matthews_corrcoef(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nMatriz de Classificação com PC=\",PC)\n",
        "conf_matrix=pd.DataFrame(conf_matrix)\n",
        "conf_matrix = np.array(conf_matrix)\n",
        "df_conf_matrix = pd.DataFrame(conf_matrix, index=['Real BP', 'Real MP'], columns=['Predito BP', 'Predito MP'])\n",
        "print(df_conf_matrix)\n",
        "print(f\"\\nPrecisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "print(f\"Mathews correlation coeficient: {MCC:.2f}\")"
      ],
      "metadata": {
        "id": "VYjIT9cG9HTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Código 11.6: Rodando a REGLOG com  método SMOTEENN\n",
        "#rodar logística utilizando BW com p values alfa=0,15\n",
        "#==============================================================================\n",
        "# Primeiro faça o upload do arquivo\n",
        "kim=pd.read_excel('/content/sample_data/Kimbal.xlsx')\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "frequenciaoriginal = y.value_counts(dropna=False).sort_index()\n",
        "print(\"frequencia amostra original :\", frequenciaoriginal)\n",
        "#==============================================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de treinamento:\", frequencia_train)\n",
        "frequencia_test = y_test['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de teste:\", frequencia_test)\n",
        "#==============================================================================\n",
        "# correção SMOTE ENN para a amostra de treinamento\n",
        "from imblearn.combine import SMOTEENN\n",
        "sme = SMOTEENN(random_state=18)\n",
        "X_train, y_train = sme.fit_resample(X_train, y_train)\n",
        "frequencia_train = y_train.value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra treinamento com SMOTE EEN:\",frequencia_train)\n",
        "#==============================================================================\n",
        "X_train = sm.add_constant(X_train)\n",
        "def backward_elimination(X_train, y_train, significance_level=0.15):\n",
        "    # Ajustando o modelo de regressão logística\n",
        "    model = sm.Logit(y_train, X_train)\n",
        "    result = model.fit(disp=0)\n",
        "    # Realizando a eliminação BWard\n",
        "    while max(result.pvalues) > significance_level:\n",
        "        # Identificar o maior p-valor\n",
        "        max_p_value = result.pvalues.idxmax()\n",
        "\n",
        "        # Remover a variável com o maior p-valor\n",
        "        #print(f\"\\nRemovendo a variável: {max_p_value} com p-valor: {result.pvalues[max_p_value]}\")\n",
        "        X_train = X_train.drop(columns=[max_p_value])\n",
        "\n",
        "        # Ajustando o modelo novamente com as variáveis restantes\n",
        "        model = sm.Logit(y_train, X_train)\n",
        "        result = model.fit(disp=0)\n",
        "    return result, X_train\n",
        "# Executando a eliminação BW com o conjunto de treino\n",
        "final_model, X_selected = backward_elimination(X_train, y_train)\n",
        "# colocando colunas em X_test para ficar igual a X_selected\n",
        "selected_columns = X_selected.columns[1:]\n",
        "# Filter X_test using selected_columns\n",
        "X_test = X_test[selected_columns]\n",
        "X_test = sm.add_constant(X_test)  # Add constant back to X_test\n",
        "\n",
        "#==============================================================================\n",
        "y_pred_prob = final_model.predict(X_test)\n",
        "\n",
        "print(\"\\n\\nAvaliação com balanceamento com SMOTEEEN =============================\")\n",
        "# Calcular a curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "# Calcular a AUC (Área sob a Curva)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Exibir a AUC\n",
        "print(f'\\nAUC da curva ROC com SMOTE EEN: {roc_auc:.2f}')\n",
        "\n",
        "#PRcurve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "# Calculando a AUC da curva Precision-Recall\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"\\nAUC da curva Precision-Recall com SMOTE EEN: {pr_auc:.2f}\")\n",
        "#==============================================================================\n",
        "# Avaliação do modelo\n",
        "\n",
        "PC=0.7\n",
        "y_pred = (y_pred_prob >= PC).astype(int)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "MCC=matthews_corrcoef(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nMatriz de Classificação com PC=\",PC)\n",
        "conf_matrix=pd.DataFrame(conf_matrix)\n",
        "conf_matrix = np.array(conf_matrix)\n",
        "df_conf_matrix = pd.DataFrame(conf_matrix, index=['Real BP', 'Real MP'], columns=['Predito BP', 'Predito MP'])\n",
        "print(\"\\n\",df_conf_matrix)\n",
        "print(f\"\\nPrecisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "print(f\"Mathews correlation coeficient: {MCC:.2f}\")"
      ],
      "metadata": {
        "id": "6HGCWNxwS0f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Código 11.7: Rodando com Random Forest sem balancear\n",
        "#==============================================================================\n",
        "# Primeiro faça o upload do arquivo\n",
        "import pandas as pd\n",
        "kim=pd.read_excel('/content/sample_data/Kimbal.xlsx')\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "frequenciaoriginal = y.value_counts(dropna=False).sort_index()\n",
        "print(\"frequencia amostra original :\", frequenciaoriginal)\n",
        "#==============================================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de treinamento:\", frequencia_train)\n",
        "frequencia_test = y_test['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de teste:\", frequencia_test)\n",
        "#==============================================================================\n",
        "## utilizando RF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#Se você não especificar bootstrap no seu modelo de Random Forest, o valor padrão será True.\n",
        "rf = RandomForestClassifier(random_state=18,\n",
        "                            min_samples_split=100,\n",
        "                            min_samples_leaf=50,\n",
        "                            bootstrap=True,\n",
        "                            oob_score=True)  # Usar amostras OOB para validação\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200], # número de rodadas\n",
        "    'max_depth': [10, 15], # profundidade da árvore / qto maior, maior o risco de overfitting\n",
        "    'max_features': ['sqrt', 'log2'] #quantidade de vars a serem selecionadas\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=-1, verbose=2)\n",
        "#n_jobs=-1: Usará todos os núcleos de CPU disponíveis no seu computador para executar a busca\n",
        "#o critério de avaliação é especificado pelo parâmetro scoring. Eu prefiro AUROC\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Mostrar os resultados de AUC para cada combinação de parâmetros\n",
        "# grid_search.cv_results_ contém os resultados de todas as combinações\n",
        "results = grid_search.cv_results_\n",
        "# Exibir os valores de AUC para cada combinação de hiperparâmetros\n",
        "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
        "    print(f\"AUC: {mean_score:.4f} | Hiperparâmetros: {params}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Melhores parâmetros encontrados:\", grid_search.best_params_)\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_prob = best_rf_model.predict_proba(X_test)[:, 1] # probMP que é class=1\n",
        "#==============================================================================\n",
        "print(\"\\n\\nAvaliação com balanceamento com RF sem balancear ===================\")\n",
        "# Calcular a curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "# Calcular a AUC (Área sob a Curva)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Exibir a AUC\n",
        "print(f'\\nAUC da curva ROC com RF sem balancear: {roc_auc:.2f}')\n",
        "\n",
        "#PRcurve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "# Calculando a AUC da curva Precision-Recall\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"\\nAUC da curva Precision-Recall com RF sem balancear: {pr_auc:.2f}\")\n",
        "#==============================================================================\n",
        "\n",
        "# Avaliação do modelo\n",
        "\n",
        "PC=0.2\n",
        "y_pred = (y_pred_prob >= PC).astype(int)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "MCC=matthews_corrcoef(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nMatriz de Classificação com PC=\",PC)\n",
        "conf_matrix=pd.DataFrame(conf_matrix)\n",
        "conf_matrix = np.array(conf_matrix)\n",
        "df_conf_matrix = pd.DataFrame(conf_matrix, index=['Real BP', 'Real MP'], columns=['Predito BP', 'Predito MP'])\n",
        "print(df_conf_matrix)\n",
        "print(f\"\\nPrecisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "print(f\"Mathews correlation coeficient: {MCC:.2f}\")"
      ],
      "metadata": {
        "id": "i_yOJy-yCZAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Código 11.8: Rodando com BalancedRandomForestClassifier\n",
        "#==============================================================================\n",
        "# Primeiro faça o upload do arquivo\n",
        "import pandas as pd\n",
        "kim=pd.read_excel('/content/sample_data/Kimbal.xlsx')\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "frequenciaoriginal = y.value_counts(dropna=False).sort_index()\n",
        "print(\"frequencia amostra original :\", frequenciaoriginal)\n",
        "#==============================================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de treinamento:\", frequencia_train)\n",
        "frequencia_test = y_test['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de teste:\", frequencia_test)\n",
        "#==============================================================================\n",
        "# correção BalancedRandomForestClassifier para a amostra de treinamento\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "clf = BalancedRandomForestClassifier(\n",
        "    sampling_strategy=\"majority\", replacement=True, max_depth=3, random_state=11,\n",
        "    bootstrap=True)\n",
        "clf.fit(X_train, y_train)\n",
        "# Prevendo\n",
        "y_pred_prob = clf.predict_proba(X_test)[:, 1]\n",
        "# Avaliação\n",
        "frequencia_train = y_train.value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra treinamento com BalancedRandomForestClassifier:\",frequencia_train)\n",
        "#==============================================================================\n",
        "print(\"\\n\\nAvaliação com balanceamento com BalancedRandomForestClassifier ========\")\n",
        "# Calcular a curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "# Calcular a AUC (Área sob a Curva)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Exibir a AUC\n",
        "print(f'\\nAUC da curva ROC com BalancedRandomForestClassifier: {roc_auc:.2f}')\n",
        "\n",
        "#PRcurve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "# Calculando a AUC da curva Precision-Recall\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"\\nAUC da curva Precision-Recall com BalancedRandomForestClassifier: {pr_auc:.2f}\")\n",
        "#==============================================================================\n",
        "# Avaliação do modelo\n",
        "\n",
        "PC=0.55\n",
        "\n",
        "y_pred = (y_pred_prob >= PC).astype(int)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "MCC=matthews_corrcoef(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nMatriz de Classificação com PC=\",PC)\n",
        "conf_matrix=pd.DataFrame(conf_matrix)\n",
        "conf_matrix = np.array(conf_matrix)\n",
        "df_conf_matrix = pd.DataFrame(conf_matrix, index=['Real BP', 'Real MP'], columns=['Predito BP', 'Predito MP'])\n",
        "print(df_conf_matrix)\n",
        "print(f\"\\nPrecisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "print(f\"Mathews correlation coeficient: {MCC:.2f}\")"
      ],
      "metadata": {
        "id": "fOFm9ydt7W-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Código 11.9: Rodando com XGBoost sem balancear\n",
        "#rodar logística sm. utilizando BW com p values alfa=0,15\n",
        "#==============================================================================\n",
        "# Primeiro faça o upload do arquivo\n",
        "import pandas as pd\n",
        "kim=pd.read_excel('/content/sample_data/Kimbal.xlsx')\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "frequenciaoriginal = y.value_counts(dropna=False).sort_index()\n",
        "print(\"frequencia amostra original :\", frequenciaoriginal)\n",
        "#==============================================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de treinamento:\", frequencia_train)\n",
        "frequencia_test = y_test['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de teste:\", frequencia_test)\n",
        "#==============================================================================\n",
        "## utilizabndo xgb\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [4,7],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'min_child_weight': [10,20]}\n",
        "model = xgb.XGBClassifier(objective='binary:logistic',\n",
        "                          eval_metric='logloss',early_stopping_rounds=10,learning_rate=0.1,\n",
        "                          use_label_encoder=False)\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_log_loss',\n",
        "    cv=3,  # Cross-validation com 3 folds\n",
        "    verbose=1,\n",
        "    n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train,  eval_set=[(X_test, y_test)], verbose=False)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Para acessar o número de iterações antes de ocorrer o early stop:\n",
        "aux=best_model.get_booster().best_iteration\n",
        "print(f'Número de árvores necessarias (early stop):  {aux}')\n",
        "\n",
        "# Predição\n",
        "y_pred_prob = best_model.predict_proba(X_test)[:, 1]\n",
        "#==============================================================================\n",
        "print(\"\\n\\nAvaliação com balanceamento com XGBoost =============================\")\n",
        "# Calcular a curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "# Calcular a AUC (Área sob a Curva)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Exibir a AUC\n",
        "print(f'\\nAUC da curva ROC com XGBoost sem balancear: {roc_auc:.2f}')\n",
        "\n",
        "#PRcurve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "# Calculando a AUC da curva Precision-Recall\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"\\nAUC da curva Precision-Recall com XGBoost sem balancear: {pr_auc:.2f}\")\n",
        "#==============================================================================\n",
        "# Avaliação do modelo\n",
        "\n",
        "PC=0.2\n",
        "y_pred = (y_pred_prob >= PC).astype(int)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "MCC=matthews_corrcoef(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nMatriz de Classificação com PC=\",PC)\n",
        "conf_matrix=pd.DataFrame(conf_matrix)\n",
        "conf_matrix = np.array(conf_matrix)\n",
        "df_conf_matrix = pd.DataFrame(conf_matrix, index=['Real BP', 'Real MP'], columns=['Predito BP', 'Predito MP'])\n",
        "print(df_conf_matrix)\n",
        "print(f\"\\nPrecisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "print(f\"Mathews correlation coeficient: {MCC:.2f}\")"
      ],
      "metadata": {
        "id": "_7PbVN_QctHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Código 11.10: rodando com XGBoost balanceando com RUS\n",
        "#==============================================================================\n",
        "# Primeiro faça o upload do arquivo\n",
        "import pandas as pd\n",
        "kim=pd.read_excel('/content/sample_data/Kimbal.xlsx')\n",
        "X= kim.drop('STATUS_MP', axis=1)\n",
        "y= kim['STATUS_MP']\n",
        "y=pd.DataFrame(y)\n",
        "frequenciaoriginal = y.value_counts(dropna=False).sort_index()\n",
        "print(\"frequencia amostra original :\", frequenciaoriginal)\n",
        "#==============================================================================\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=18)\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de treinamento:\", frequencia_train)\n",
        "frequencia_test = y_test['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de teste:\", frequencia_test)\n",
        "\n",
        "#==============================================================================\n",
        "#balanceando com RUS\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
        "frequencia_train = y_train['STATUS_MP'].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nFrequencia amostra de treinamento com RUS:\", frequencia_train)\n",
        "#==============================================================================\n",
        "## utilizabndo xgb\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [4,7],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'min_child_weight': [10,20]}\n",
        "model = xgb.XGBClassifier(objective='binary:logistic',\n",
        "                          eval_metric='logloss',early_stopping_rounds=10,learning_rate=0.1,\n",
        "                          use_label_encoder=False)\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_log_loss',\n",
        "    cv=3,  # Cross-validation com 3 folds\n",
        "    verbose=1,\n",
        "    n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train,  eval_set=[(X_test, y_test)], verbose=False)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Para acessar o número de iterações antes de ocorrer o early stop:\n",
        "aux=best_model.get_booster().best_iteration\n",
        "print(f'Número de árvores necessarias (early stop):  {aux}')\n",
        "\n",
        "# Predição e cálculo do LogLoss\n",
        "y_pred_prob = best_model.predict_proba(X_test)[:, 1]\n",
        "#==============================================================================\n",
        "print(\"\\n\\nAvaliação com balanceamento com XGBoost =============================\")\n",
        "# Calcular a curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "# Calcular a AUC (Área sob a Curva)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Exibir a AUC\n",
        "print(f'\\nAUC da curva ROC com XGBoost sem balancear: {roc_auc:.2f}')\n",
        "\n",
        "#PRcurve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "# Calculando a AUC da curva Precision-Recall\n",
        "pr_auc = auc(recall, precision)\n",
        "print(f\"\\nAUC da curva Precision-Recall com XGBoost sem balancear: {pr_auc:.2f}\")\n",
        "#==============================================================================\n",
        "\n",
        "# Avaliação do modelo\n",
        "\n",
        "PC=0.6\n",
        "y_pred = (y_pred_prob >= PC).astype(int)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "MCC=matthews_corrcoef(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nMatriz de Classificação com PC=\",PC)\n",
        "conf_matrix=pd.DataFrame(conf_matrix)\n",
        "conf_matrix = np.array(conf_matrix)\n",
        "df_conf_matrix = pd.DataFrame(conf_matrix, index=['Real BP', 'Real MP'], columns=['Predito BP', 'Predito MP'])\n",
        "print(df_conf_matrix)\n",
        "print(f\"\\nPrecisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "print(f\"Mathews correlation coeficient: {MCC:.2f}\")"
      ],
      "metadata": {
        "id": "1wh3YuGfefAR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}